{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takudzwa-coder/tools/blob/master/Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS4R01Y_vKx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d7adee-a857-4971-e597-5da85bfb322e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7Tiz4YwpzU8V"
      },
      "outputs": [],
      "source": [
        "# Module imports, do not modify these\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MekCZCozzU8j"
      },
      "outputs": [],
      "source": [
        "# Comment the line below if you'd like to use the GPU; default device is CPU\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "# Don't modify these\n",
        "IMAGE_HEIGHT = 60\n",
        "IMAGE_WIDTH = 60\n",
        "CHANNELS = 3\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzUuEzKbzU8l"
      },
      "outputs": [],
      "source": [
        "def getDataGenerators():\n",
        "    \"\"\"\n",
        "    This function creates two data generators: a training data generator and a validation data generator.\n",
        "    Both generators can be created by sub-setting an ImageDataGenerator object. The ImageDataGenerator object is\n",
        "    responsible for (limited) image pre-processing, dataset splitting and augmentation.\n",
        "\n",
        "    Task: create the image data generator and sub-set it into two generators: a training data generator and a\n",
        "    validation data generator.\n",
        "\n",
        "    Image data generator requirements:\n",
        "        - normalise input images by dividing by 255.\n",
        "        - set the amount validation data to be 10% of the training data\n",
        "\n",
        "    Sub-set data generator requirements:\n",
        "        - Use target image sizes as defined above\n",
        "        - Use the batch size as defined above\n",
        "        - Class mode must be 'categorical'\n",
        "        - Color mode must be RGB\n",
        "        - Enable dataset shuffling\n",
        "\n",
        "    Hint: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "    Return: dataGenerator1, dataGenerator2 (You may use any variable name; this is just an example)\n",
        "    \"\"\"\n",
        "\n",
        "    datasetDirPath = \"./data/train/\"\n",
        "\n",
        "    # TODO: Set the ImageDataGeneratorObject\n",
        "    ImageDataGeneratorObject = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    datasetDirPath, #done\n",
        "    labels=\"inferred\", \n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=BATCH_SIZE, #done\n",
        "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),#done\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "    # TODO: Set the training data generator subset\n",
        "\n",
        "    # TODO: Set the validation data generator subset\n",
        "\n",
        "    return trainGenerator, validationGenerator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-ap_2gnzU8u"
      },
      "outputs": [],
      "source": [
        "def buildModel():\n",
        "    \"\"\"\n",
        "    This function defines a tensorflow model to be used for training and testing. The model has to be defined and\n",
        "    compiled with an associated optimizer and loss function.\n",
        "\n",
        "    Tasks:\n",
        "        - Define the input layer for the CNN model\n",
        "        - Add a global average pooling layer to the model output\n",
        "        - add a batch normalization layer\n",
        "        - add a dense layer\n",
        "            - 512 units\n",
        "            - ReLU activation function\n",
        "        - add a dense layer\n",
        "            - 256 units\n",
        "            - ReLU activation function\n",
        "        - add a dense layer\n",
        "            - 2 units\n",
        "            - softmax activation function\n",
        "        - Use SDG optimizer with a learning rate of 1e-5\n",
        "\n",
        "    Hint: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer\n",
        "    Hint: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "\n",
        "    :return: compiled TF model\n",
        "    \"\"\"\n",
        "    # TODO: Every model requires an input layer. Define the input layer using the above declared height,\n",
        "    #  width and channels constants\n",
        "    inputs = Input(shape=(None, None, None))\n",
        "    \n",
        "    # Store the EfficientNetB0 model in a variable. Check the parameters.\n",
        "    baseModel = EfficientNetB0(include_top=False, weights=None, input_tensor=inputs, classes=2)\n",
        "    baseModel.trainable = True\n",
        "    \n",
        "    # Set model output\n",
        "    baseModelOutput = baseModel.output\n",
        "    \n",
        "    # TODO: add specified layers\n",
        "    out = None\n",
        "    \n",
        "    # Define end-to-end model\n",
        "    model = tf.keras.Model(inputs, out, name=\"EfficientNet\")\n",
        "    \n",
        "    # TODO: Set SGD optimizer\n",
        "    \n",
        "    # Set metrics (feel free to add additional metrics)\n",
        "    METRICS = [\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "    ]\n",
        "    \n",
        "    # Compile the model and set the loss function.\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=METRICS)\n",
        "    \n",
        "    # Return model\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZgxZIkazU80"
      },
      "outputs": [],
      "source": [
        "\n",
        "def trainer():\n",
        "    \"\"\"\n",
        "    This function controls model training. Steps for this function include:\n",
        "        - retrieving the dataset generators\n",
        "        - building the TF model\n",
        "        - training the model\n",
        "        - saving the trained model\n",
        "    :return: trained TF model\n",
        "    \"\"\"\n",
        "    # Get the train and validation generators\n",
        "    trainGen, valGen = getDataGenerators()\n",
        "    # Get the model\n",
        "    model = buildModel()\n",
        "    # Fit the model to the data; use the .fit function\n",
        "    model.fit(\n",
        "        x=trainGen,\n",
        "        steps_per_epoch=trainGen.samples // BATCH_SIZE,\n",
        "        validation_data=valGen,\n",
        "        validation_steps=valGen.samples // BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        verbose=1)\n",
        "\n",
        "    model.save(\"ENmodel.h5\")\n",
        "\n",
        "    # Return trained model\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reLWBOLozU83"
      },
      "outputs": [],
      "source": [
        "\n",
        "def getPredictions(image):\n",
        "    model = tf.keras.models.load_model(\"ENmodel.h5\")\n",
        "    # print(model.summary())\n",
        "    rgbImage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    rgbImage = cv2.resize(rgbImage, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "    rgbImage = rgbImage.astype(np.float64)\n",
        "    rgbImage = np.expand_dims(rgbImage, axis=0)\n",
        "    rgbImage = rgbImage / 255.\n",
        "    predictions = model.predict(rgbImage)\n",
        "    print(predictions)\n",
        "    return predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ_-btJJzU85"
      },
      "outputs": [],
      "source": [
        "\n",
        "def modelTesting():\n",
        "    datasetDirPath = \"./data/test/\"\n",
        "    classes = [\"live/\", \"spoof/\"]\n",
        "    model = tf.keras.models.load_model(\"ENmodel.h5\")\n",
        "    xTest = np.empty((400, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS), dtype=np.float64)\n",
        "    y = np.empty((400, 2), dtype=np.float64)\n",
        "\n",
        "    classImageNames = os.listdir(datasetDirPath + classes[0])\n",
        "\n",
        "    for i in range(200):\n",
        "        image_1 = cv2.imread(datasetDirPath + classes[0] + classImageNames[i])\n",
        "        image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)\n",
        "        image_1 = cv2.resize(image_1, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "        image_1 = np.array(image_1)\n",
        "        image_1 = image_1 / 255.\n",
        "        xTest[i,] = image_1\n",
        "        y[i] = [1.0, 0.0]\n",
        "\n",
        "    classImageNames = os.listdir(datasetDirPath + classes[1])\n",
        "\n",
        "    for i in range(200):\n",
        "        image_1 = cv2.imread(datasetDirPath + classes[1] + classImageNames[i])\n",
        "        image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)\n",
        "        image_1 = cv2.resize(image_1, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "        image_1 = np.array(image_1)\n",
        "        image_1 = image_1 / 255.\n",
        "        xTest[200 + i,] = image_1\n",
        "        y[200 + i] = [0.0, 1.0]\n",
        "\n",
        "    # Evaluate the restored model\n",
        "    loss, acc = model.evaluate(xTest, y, verbose=2)\n",
        "    print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Model training\n",
        "    model = trainer()\n",
        "    # Model testing\n",
        "    modelTesting()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzl6L1M3zU89"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05lQzskZzU8-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Q1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}